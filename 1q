package main

import (
	"fmt"
	"sort"
	"strconv"
	"strings"
	"sync"
	//"sync/atomic"
)

var mx sync.Mutex

func SingleHash(in, out chan interface{}) {
	for recv := range in {
		if recv, ok := recv.(int); ok {
			data := strconv.Itoa(recv)
			out1, out2 := make(chan string), make(chan string)
			go func() {
				out1 <- DataSignerCrc32(data)
			}()
			go func() {
				out2 <- DataSignerCrc32(DataSignerMd5(data))
			}()
			out <- ((<-out1) + "~" + (<-out2))
		}
	}
}

func MultiHash(in, out chan interface{}) {
	for recv := range in {
		if data, ok := recv.(string); ok {
			results := make([]string, 6)
			for th := 0; th < 6; th++ {
				go func(th int) {
					mx.Lock()
					results[th] = DataSignerCrc32(strconv.Itoa(th) + data)
					mx.Unlock()
				}(th)
				mx.Lock()
				fmt.Println(results)
				mx.Unlock()
			}
			mx.Lock()
			out <- strings.Join(results, "")
			mx.Unlock()
		}
	}
}

func CombineResults(in, out chan interface{}) {
	ss := make([]string, 0)
	for recv := range in {
		if data, ok := recv.(string); ok {
			ss = append(ss, data)
		}
	}
	sort.Strings(ss)
	out <- strings.Join(ss, "_")
}

func do_work(worker job, wg *sync.WaitGroup, in, out chan interface{}) {
	defer wg.Done()
	defer close(out)
	worker(in, out)
}

func ExecutePipeline(workers ...job) {
	var wg = &sync.WaitGroup{}
	channels := make([]chan interface{}, len(workers)+1)
	for i, _ := range channels {
		channels[i] = make(chan interface{})
	}
	for i, worker := range workers {
		in, out := channels[i], channels[i+1]
		wg.Add(1)
		go do_work(worker, wg, in, out)
	}
	wg.Wait()
}

func main() {
	workflow := make([]job, 5)
	workflow[0] = job(func(in, out chan interface{}) {
		for i := 0; i < 2; i++ {
			out <- i
		}
	})
	workflow[1] = job(SingleHash)
	workflow[2] = job(MultiHash)
	workflow[3] = job(CombineResults)
	workflow[4] = job(func(in, out chan interface{}) {
		for res := range in {
			fmt.Println(res)
		}
	})
	ExecutePipeline(workflow...)
}
